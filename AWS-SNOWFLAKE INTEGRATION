--                                                    for working in aws
create OR REPLACE DATABASE DEMO_DATABASE;
use DEMO_DATABASE;

DROP TABLE PATIENTS

CREATE OR REPLACE TABLE HEALTHCARE(
Patientid VARCHAR(15),	
gender CHAR(8),	
age VARCHAR(5)	,
hypertension CHAR(20),	
heart_disease CHAR(20),	
ever_married CHAR(30),	
work_type VARCHAR(60),	
Residence_type CHAR(30)	,
avg_glucose_level VARCHAR(20),	
bmi VARCHAR(20)	,
smoking_status	VARCHAR(20),
stroke CHAR(20)
);
CREATE OR REPLACE STORAGE integration s3_int
TYPE = EXTERNAL_STAGE
STORAGE_PROVIDER = S3
ENABLED = TRUE
STORAGE_AWS_ROLE_ARN ='arn:aws:iam::380939848760:role/snowpiperole'
STORAGE_ALLOWED_LOCATIONS =('s3://raviawsbucket11');
desc integration s3_int;


CREATE OR REPLACE STAGE HEALTHCARE_SP
URL ='s3://raviawsbucket11'
--credentials=(aws_key_id='AKIAXQKR3H3PSG72XFMK'aws_secret_key='eKL6a6FjlQHic4s8Ne712Aelzg2ou4j6tNsVvFq5')

file_format=CSV_HEALTHCARE
storage_integration =s3_int;

SHOW STAGES;

LIST @HEALTHCARE_SP;

--CREATE SNOWPIPE THAT RECOGNISES CSV THAT ARE INGESTED FROM EXTERNAL STAGE AND COPIES THE DATA HEALTHCARE INTO TABLE
--The AUTO_INGEST=true parameter specifies to read event notifications sent from an S3 bucket to an SQS queue when new data is ready to load.


CREATE OR REPLACE PIPE HEALTHCARE_SNOWPIPE AUTO_INGEST = TRUE AS
COPY INTO "DEMO_DATABASE"."PUBLIC"."HEALTHCARE"
FROM @HEALTHCARE_SP
FILE_FORMAT =CSV_HEALTHCARE;


SHOW PIPES;

SELECT count(*) FROM HEALTHCARE;

select * from HEALTHCARE;
alter pipe HEALTHCARE_SNOWPIPE refresh;

SELECT SYSTEM$PIPE_STATUS('HEALTHCARE_SNOWPIPE');






